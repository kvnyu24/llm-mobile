{
  "timestamp": "20250423_015610",
  "comparison_type": "memory_quantization_vs_baseline",
  "model_name": "gpt2",
  "prompt": "Test memory compression, layer skipping, and token pruning with pruning action",
  "tokens": 100,
  "device": "auto",
  "optimized_run": {
    "label": "Quantized (Low Budget)",
    "flags": "--memory-opt --mem-budget 5",
    "loop_time_s": 25.35,
    "peak_memory_mb": 4.5,
    "layers_skipped": 0,
    "quant_events": 236,
    "layers_offloaded": 0,
    "tokens_pruned": 0
  },
  "baseline_run": {
    "label": "Unquantized (High Budget)",
    "flags": "--memory-opt --mem-budget 10000",
    "loop_time_s": 25.76,
    "peak_memory_mb": 8.02,
    "layers_skipped": 0,
    "quant_events": 0,
    "layers_offloaded": 0,
    "tokens_pruned": 0
  }
}
