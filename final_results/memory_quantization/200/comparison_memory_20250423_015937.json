{
  "timestamp": "20250423_015937",
  "comparison_type": "memory_quantization_vs_baseline",
  "model_name": "gpt2",
  "prompt": "Test memory compression, layer skipping, and token pruning with pruning action",
  "tokens": 200,
  "device": "auto",
  "optimized_run": {
    "label": "Quantized (Low Budget)",
    "flags": "--memory-opt --mem-budget 5",
    "loop_time_s": 102.49,
    "peak_memory_mb": 4.5,
    "layers_skipped": 0,
    "quant_events": 1244,
    "layers_offloaded": 0,
    "tokens_pruned": 0
  },
  "baseline_run": {
    "label": "Unquantized (High Budget)",
    "flags": "--memory-opt --mem-budget 10000",
    "loop_time_s": 99.31,
    "peak_memory_mb": 15.05,
    "layers_skipped": 0,
    "quant_events": 0,
    "layers_offloaded": 0,
    "tokens_pruned": 0
  }
}
