INFO:hybrid_inference:Log level set to: INFO
INFO:hybrid_inference:Set pad_token to eos_token for tokenizer.
INFO:hybrid_inference:Using device: cpu
INFO:hybrid_inference:Loading model: gpt2...
INFO:hybrid_inference:Using float32 for model loading on CPU.
INFO:hybrid_inference:=====================================================
INFO:hybrid_inference:HYBRID INFERENCE - REAL MODEL EXECUTION
INFO:hybrid_inference:=====================================================
INFO:hybrid_inference:Model: gpt2
INFO:hybrid_inference:Device: cpu
INFO:hybrid_inference:Model dimensions: 768d, 12 layers, 12 attention heads
INFO:hybrid_inference:Prompt: "Test memory compression, layer skipping, and token pruning with pruning action"
INFO:hybrid_inference:Max New Tokens: 100
INFO:hybrid_inference:Enabled optimizations:
INFO:hybrid_inference:  - Token Pruning: True
INFO:hybrid_inference:  - Layer Opt (Skip/Compress): True
INFO:hybrid_inference:  - Memory Management (Quant): True
INFO:hybrid_inference:  - Edge-Cloud Partitioning: True (Logic not active)
INFO:hybrid_inference:=====================================================
INFO:hybrid_inference:Initializing Memory Manager...
INFO:memory_manager:Memory Manager initialized with 5MB budget, threshold 90%, Quantization: True
INFO:hybrid_inference:Initializing Token Pruner...
INFO:hybrid_inference:Initializing Layer Compression/Skipping Manager...
INFO:hybrid_inference:Initializing Edge-Cloud Manager...
INFO:edge_cloud_manager:EdgeCloudManager initialized for 12 layers.
INFO:hybrid_inference:Registering pre-forward hooks for layer skipping on 12 layers...
INFO:hybrid_inference:Successfully registered 12 hooks.
INFO:hybrid_inference:Starting inference loop for 100 tokens...
INFO:hybrid_inference:  Step 1 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
WARNING:token_pruning.token_pruner:Expected query length (Q) of 1 for scoring, but got 15. Using only the first query position.
INFO:hybrid_inference:  Step 2 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:  Step 3 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:  Step 4 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:  Step 5 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:  Step 6 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:  Step 7 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:  Step 8 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:  Step 9 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:  Step 10 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:  Step 11 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during index_select for layer 0: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 25, 64]), Value=torch.Size([1, 12, 25, 64]), Index=torch.Size([23])
ERROR:token_pruning.token_pruner:Error during index_select for layer 1: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 25, 64]), Value=torch.Size([1, 12, 25, 64]), Index=torch.Size([23])
ERROR:token_pruning.token_pruner:Error during index_select for layer 2: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 20, 64]), Value=torch.Size([1, 12, 20, 64]), Index=torch.Size([23])
ERROR:token_pruning.token_pruner:Error during index_select for layer 3: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 20, 64]), Value=torch.Size([1, 12, 20, 64]), Index=torch.Size([23])
ERROR:token_pruning.token_pruner:Error during index_select for layer 4: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 22, 64]), Value=torch.Size([1, 12, 22, 64]), Index=torch.Size([23])
ERROR:token_pruning.token_pruner:Error during index_select for layer 5: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 25, 64]), Value=torch.Size([1, 12, 25, 64]), Index=torch.Size([23])
INFO:token_pruning.token_pruner:Pruned 2 tokens. New seq len: 23
INFO:hybrid_inference:  Step 12 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during index_select for layer 0: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 26, 64]), Value=torch.Size([1, 12, 26, 64]), Index=torch.Size([22])
ERROR:token_pruning.token_pruner:Error during index_select for layer 1: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 26, 64]), Value=torch.Size([1, 12, 26, 64]), Index=torch.Size([22])
ERROR:token_pruning.token_pruner:Error during index_select for layer 2: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 20, 64]), Value=torch.Size([1, 12, 20, 64]), Index=torch.Size([22])
ERROR:token_pruning.token_pruner:Error during index_select for layer 3: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 20, 64]), Value=torch.Size([1, 12, 20, 64]), Index=torch.Size([22])
ERROR:token_pruning.token_pruner:Error during index_select for layer 4: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 23, 64]), Value=torch.Size([1, 12, 23, 64]), Index=torch.Size([22])
ERROR:token_pruning.token_pruner:Error during index_select for layer 5: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 26, 64]), Value=torch.Size([1, 12, 26, 64]), Index=torch.Size([22])
INFO:token_pruning.token_pruner:Pruned 4 tokens. New seq len: 22
INFO:hybrid_inference:  Step 13 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during index_select for layer 0: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 27, 64]), Value=torch.Size([1, 12, 27, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 1: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 27, 64]), Value=torch.Size([1, 12, 27, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 2: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 21, 64]), Value=torch.Size([1, 12, 21, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 3: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 21, 64]), Value=torch.Size([1, 12, 21, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 4: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 24, 64]), Value=torch.Size([1, 12, 24, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 5: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 27, 64]), Value=torch.Size([1, 12, 27, 64]), Index=torch.Size([24])
INFO:token_pruning.token_pruner:Pruned 3 tokens. New seq len: 24
INFO:hybrid_inference:  Step 14 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during index_select for layer 0: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 28, 64]), Value=torch.Size([1, 12, 28, 64]), Index=torch.Size([23])
ERROR:token_pruning.token_pruner:Error during index_select for layer 1: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 28, 64]), Value=torch.Size([1, 12, 28, 64]), Index=torch.Size([23])
ERROR:token_pruning.token_pruner:Error during index_select for layer 2: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 21, 64]), Value=torch.Size([1, 12, 21, 64]), Index=torch.Size([23])
ERROR:token_pruning.token_pruner:Error during index_select for layer 3: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 21, 64]), Value=torch.Size([1, 12, 21, 64]), Index=torch.Size([23])
ERROR:token_pruning.token_pruner:Error during index_select for layer 4: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 25, 64]), Value=torch.Size([1, 12, 25, 64]), Index=torch.Size([23])
ERROR:token_pruning.token_pruner:Error during index_select for layer 5: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 28, 64]), Value=torch.Size([1, 12, 28, 64]), Index=torch.Size([23])
INFO:token_pruning.token_pruner:Pruned 5 tokens. New seq len: 23
INFO:hybrid_inference:  Step 15 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during index_select for layer 0: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 29, 64]), Value=torch.Size([1, 12, 29, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 1: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 29, 64]), Value=torch.Size([1, 12, 29, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 2: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 22, 64]), Value=torch.Size([1, 12, 22, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 3: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 22, 64]), Value=torch.Size([1, 12, 22, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 4: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 25, 64]), Value=torch.Size([1, 12, 25, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 5: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 29, 64]), Value=torch.Size([1, 12, 29, 64]), Index=torch.Size([24])
INFO:token_pruning.token_pruner:Pruned 5 tokens. New seq len: 24
INFO:hybrid_inference:  Step 16 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during index_select for layer 0: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 30, 64]), Value=torch.Size([1, 12, 30, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 1: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 30, 64]), Value=torch.Size([1, 12, 30, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 2: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 22, 64]), Value=torch.Size([1, 12, 22, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 3: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 22, 64]), Value=torch.Size([1, 12, 22, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 4: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 26, 64]), Value=torch.Size([1, 12, 26, 64]), Index=torch.Size([24])
ERROR:token_pruning.token_pruner:Error during index_select for layer 5: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 30, 64]), Value=torch.Size([1, 12, 30, 64]), Index=torch.Size([24])
INFO:token_pruning.token_pruner:Pruned 6 tokens. New seq len: 24
INFO:hybrid_inference:  Step 17 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during index_select for layer 0: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 31, 64]), Value=torch.Size([1, 12, 31, 64]), Index=torch.Size([25])
ERROR:token_pruning.token_pruner:Error during index_select for layer 1: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 31, 64]), Value=torch.Size([1, 12, 31, 64]), Index=torch.Size([25])
ERROR:token_pruning.token_pruner:Error during index_select for layer 2: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 23, 64]), Value=torch.Size([1, 12, 23, 64]), Index=torch.Size([25])
ERROR:token_pruning.token_pruner:Error during index_select for layer 3: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 23, 64]), Value=torch.Size([1, 12, 23, 64]), Index=torch.Size([25])
ERROR:token_pruning.token_pruner:Error during index_select for layer 4: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 26, 64]), Value=torch.Size([1, 12, 26, 64]), Index=torch.Size([25])
ERROR:token_pruning.token_pruner:Error during index_select for layer 5: 'TokenPruner' object has no attribute 'kv_cache_dim'
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 311, in prune_state
    pruned_keys = torch.index_select(layer_keys, dim=self.kv_cache_dim, index=keep_indices_tensor)
                                                     ^^^^^^^^^^^^^^^^^
AttributeError: 'TokenPruner' object has no attribute 'kv_cache_dim'
ERROR:token_pruning.token_pruner:  Shapes: Key=torch.Size([1, 12, 31, 64]), Value=torch.Size([1, 12, 31, 64]), Index=torch.Size([25])
INFO:token_pruning.token_pruner:Pruned 6 tokens. New seq len: 25
INFO:hybrid_inference:  Step 18 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -5: [1, -5]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -5: [1, -5]
INFO:hybrid_inference:  Step 19 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -3: [1, -3]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -3: [1, -3]
INFO:hybrid_inference:  Step 20 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -5: [1, -5]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -5: [1, -5]
INFO:hybrid_inference:  Step 21 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -5: [1, -5]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -5: [1, -5]
INFO:hybrid_inference:  Step 22 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -6: [1, -6]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -6: [1, -6]
INFO:hybrid_inference:  Step 23 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -6: [1, -6]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -6: [1, -6]
INFO:hybrid_inference:  Step 24 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -12: [1, -12]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -12: [1, -12]
INFO:hybrid_inference:  Step 25 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -5: [1, -5]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -5: [1, -5]
INFO:hybrid_inference:  Step 26 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -12: [1, -12]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -12: [1, -12]
INFO:hybrid_inference:  Step 27 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -11: [1, -11]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -11: [1, -11]
INFO:hybrid_inference:  Step 28 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -10: [1, -10]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -10: [1, -10]
INFO:hybrid_inference:  Step 29 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -9: [1, -9]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -9: [1, -9]
INFO:hybrid_inference:  Step 30 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -9: [1, -9]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -9: [1, -9]
INFO:hybrid_inference:  Step 31 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -9: [1, -9]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -9: [1, -9]
INFO:hybrid_inference:  Step 32 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -8: [1, -8]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -8: [1, -8]
INFO:hybrid_inference:  Step 33 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -7: [1, -7]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -7: [1, -7]
INFO:hybrid_inference:  Step 34 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -6: [1, -6]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -6: [1, -6]
INFO:hybrid_inference:  Step 35 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -7: [1, -7]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -7: [1, -7]
INFO:hybrid_inference:  Step 36 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -5: [1, -5]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -5: [1, -5]
INFO:hybrid_inference:  Step 37 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -8: [1, -8]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -8: [1, -8]
INFO:hybrid_inference:  Step 38 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -5: [1, -5]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -5: [1, -5]
INFO:hybrid_inference:  Step 39 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -6: [1, -6]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -6: [1, -6]
INFO:hybrid_inference:  Step 40 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -12: [1, -12]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -12: [1, -12]
INFO:hybrid_inference:  Step 41 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -7: [1, -7]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -7: [1, -7]
INFO:hybrid_inference:  Step 42 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -7: [1, -7]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -7: [1, -7]
INFO:hybrid_inference:  Step 43 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -4: [1, -4]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -4: [1, -4]
INFO:hybrid_inference:  Step 44 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -6: [1, -6]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -6: [1, -6]
INFO:hybrid_inference:  Step 45 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -5: [1, -5]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -5: [1, -5]
INFO:hybrid_inference:  Step 46 Partition: Local=[0, 1, 2, 3, 4, 5], Remote=[6, 7, 8, 9, 10, 11]
INFO:hybrid_inference:    [Offload Check] Layer 6 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 7 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 8 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 9 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 10 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
INFO:hybrid_inference:    [Offload Check] Layer 11 is in remote_layers: [6, 7, 8, 9, 10, 11]. Incrementing counter.
ERROR:token_pruning.token_pruner:Error during state pruning: Trying to create tensor with negative dimension -5: [1, -5]
Traceback (most recent call last):
  File "/Users/kevinyu/Projects/llm-mobile/src/token_pruning/token_pruner.py", line 275, in prune_state
    new_mask = torch.zeros((batch_size, new_mask_len), dtype=torch.long, device=device)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to create tensor with negative dimension -5: [1, -5]
